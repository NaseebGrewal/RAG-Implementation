{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation (RAG) Notebook Overview\n",
    "\n",
    "This notebook demonstrates the complete workflow of a simple RAG system designed to identify potentially suspicious organizations from a fictional dataset. The main steps include:\n",
    "\n",
    "1. **Dependency Installation:**  \n",
    "   Ensuring that all necessary Python packages are installed for the notebook to run smoothly.\n",
    "\n",
    "2. **Data Indexing:**  \n",
    "   Loading and preparing a dataset of organization descriptions.\n",
    "\n",
    "3. **Embedding Generation:**  \n",
    "   Using a pre-trained SentenceTransformer model to convert text descriptions into numerical embeddings.\n",
    "\n",
    "4. **Similarity Search:**  \n",
    "   Leveraging FAISS to perform efficient vector similarity searches between a user query and document embeddings.\n",
    "\n",
    "5. **Prompt Construction:**  \n",
    "   Building a query prompt by integrating the top-k retrieved document details.\n",
    "\n",
    "6. **Response Generation:**  \n",
    "   Using the Hugging Face Mistral API to generate human-like answers based on the constructed prompt.\n",
    "\n",
    "\n",
    "\n",
    "Follow the cells sequentially to install dependencies, index the data, generate embeddings, perform the similarity search, and finally produce a detailed, human-like response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (1.10.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (2.2.4)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.13/site-packages (from sentence_transformers->-r requirements.txt (line 1)) (4.51.1)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from sentence_transformers->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.13/site-packages (from sentence_transformers->-r requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (from sentence_transformers->-r requirements.txt (line 1)) (1.6.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.13/site-packages (from sentence_transformers->-r requirements.txt (line 1)) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.13/site-packages (from sentence_transformers->-r requirements.txt (line 1)) (0.30.2)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.13/site-packages (from sentence_transformers->-r requirements.txt (line 1)) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.13/site-packages (from sentence_transformers->-r requirements.txt (line 1)) (4.13.1)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from faiss-cpu->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 1)) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 1)) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 1)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 1)) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 1)) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS Index Creation and Data Embedding Details\n",
    "\n",
    "This cell contains key functions that enable the Retrieval-Augmented Generation (RAG) system to process and index the dataset. The main steps are:\n",
    "\n",
    "1. **Data Loading & Preprocessing:**\n",
    "   - **Function:** `load_and_preprocess_data`\n",
    "   - **Purpose:**  \n",
    "     Reads the raw dataset file from the specified `FILE_PATH` and parses it using a regular expression.  \n",
    "     It extracts each document's ID, title, and description, returning a list of dictionaries.\n",
    "\n",
    "2. **Embedding Generation:**\n",
    "   - **Function:** `embed_texts`\n",
    "   - **Purpose:**  \n",
    "     Uses a pre-trained SentenceTransformer model (default: `\"BAAI/bge-small-en-v1.5\"`) to generate vector embeddings for each document.  \n",
    "     The embeddings are computed from a concatenation of the document title and text, then returned as a NumPy array.\n",
    "\n",
    "3. **FAISS Index Construction:**\n",
    "   - **Function:** `create_faiss_index`\n",
    "   - **Purpose:**  \n",
    "     Combines the data loading and embedding functions to build a FAISS index with L2 distance (using `faiss.IndexFlatL2`).  \n",
    "     It indexes the embeddings and also creates a mapping between index positions and the original document dictionaries for later retrieval.\n",
    "\n",
    "> **Note:**  \n",
    "> Ensure the `.env` file is configured with the correct `FILE_PATH` to your dataset before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theowner/Documents/GitHub/Hawk-Submission/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "# Constants\n",
    "FILE_PATH = os.getenv(\"FILE_PATH\")\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset from the given file path.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the text file containing documents.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of dictionaries containing parsed document information.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        raw_text = file.read()\n",
    "\n",
    "    pattern = r\"Document (\\d+): (.*?)\\nDescription:\\n(.*?)(?=\\nDocument \\d+:|\\Z)\"\n",
    "    matches = re.findall(pattern, raw_text, re.DOTALL)\n",
    "\n",
    "    documents = [\n",
    "        {\n",
    "            \"doc_id\": int(doc_id),\n",
    "            \"title\": title.strip(),\n",
    "            \"text\": description.strip(),\n",
    "        }\n",
    "        for doc_id, title, description in matches\n",
    "    ]\n",
    "    return documents\n",
    "\n",
    "\n",
    "def embed_texts(\n",
    "    documents: List[Dict[str, Any]], model_name: str = \"BAAI/bge-small-en-v1.5\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Embed the texts using a SentenceTransformer model.\n",
    "\n",
    "    Args:\n",
    "        documents (List[Dict[str, Any]]): List of documents with 'title' and 'text'.\n",
    "        model_name (str): Name of the SentenceTransformer model to use.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Embeddings for the input documents.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    corpus = [f\"{doc['title']}: {doc['text']}\" for doc in documents]\n",
    "    embeddings = model.encode(corpus, show_progress_bar=True)\n",
    "    return np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "\n",
    "def create_faiss_index() -> Tuple[faiss.Index, Dict[int, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Create a FAISS index from the embedded document vectors.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[faiss.Index, Dict[int, Dict[str, Any]]]: \n",
    "            FAISS index and mapping from index ID to document.\n",
    "    \"\"\"\n",
    "    file_path = os.getenv(\"FILE_PATH\")\n",
    "    if not file_path:\n",
    "        raise ValueError(\"FILE_PATH environment variable is not set.\")\n",
    "\n",
    "    documents = load_and_preprocess_data(file_path)\n",
    "    embeddings = embed_texts(documents)\n",
    "\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    id_to_doc = {i: doc for i, doc in enumerate(documents)}\n",
    "\n",
    "    print(f\"FAISS index created with {index.ntotal} documents.\")\n",
    "    return index, id_to_doc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Query Function Details\n",
    "\n",
    "This cell defines the `search_query` function, which is responsible for retrieving the top matching document snippets based on a user query. The key steps include:\n",
    "\n",
    "1. **Query Encoding:**\n",
    "   - Uses the same pre-trained SentenceTransformer model (`BAAI/bge-small-en-v1.5`) to encode the input query into a vector representation.\n",
    "\n",
    "2. **Similarity Search:**\n",
    "   - Performs a FAISS search on the pre-built index using the query embedding.\n",
    "   - Retrieves the top `k` similar documents from the index based on Euclidean (L2) distance.\n",
    "\n",
    "3. **Results Display:**\n",
    "   - Iterates over the retrieved results and prints each document's rank, title, description, and distance.\n",
    "   - Aggregates the title and description into a context list for potential further use.\n",
    "\n",
    "> **Note:**  \n",
    "> This function is optimized for a conversational AI context, enabling users to ask questions and receive relevant document snippets as answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Query Funcion for Index\n",
    "#  This function takes a query string, encodes it using the same model used for embedding the documents,\n",
    "#  and performs a similarity search in the FAISS index to retrieve the top k most similar documents.\n",
    "#  It returns the titles and descriptions of the top k documents along with their distances from the query.\n",
    "#  The function also prints the results in a readable format.\n",
    "#  The function is designed to be used in a conversational AI context, where the user can ask questions\n",
    "#  and receive relevant document snippets as answers.\n",
    "#  ========================================================================\n",
    "#  Search Query Function\n",
    "#  ========================================================================\n",
    "from typing import Any, Dict, List, Tuple\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "\n",
    "def search_query(\n",
    "    index: faiss.Index,\n",
    "    id_to_doc: Dict[int, Dict[str, Any]],\n",
    "    query: str,\n",
    "    model: SentenceTransformer = SentenceTransformer(\"BAAI/bge-small-en-v1.5\"),\n",
    "    top_k: int = 3,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Encode the query, perform FAISS similarity search, and return top matching contexts.\n",
    "\n",
    "    Args:\n",
    "        index (faiss.Index): The FAISS index containing document embeddings.\n",
    "        id_to_doc (Dict[int, Dict[str, Any]]): Mapping from index position to document.\n",
    "        query (str): User query string.\n",
    "        model (SentenceTransformer): Preloaded SentenceTransformer model.\n",
    "        top_k (int): Number of top results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of top document contexts as strings.\n",
    "    \"\"\"\n",
    "    # Encode the query\n",
    "    query_embedding = model.encode([query]).astype(\"float32\")\n",
    "\n",
    "    # Search the FAISS index\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    print(\"=======================================================================\")\n",
    "    print(f\"Top {top_k} results retrieved for the Query: {query}\")\n",
    "    print(\"=======================================================================\")\n",
    "\n",
    "\n",
    "    context: List[str] = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        title = id_to_doc[idx][\"title\"]\n",
    "        description = id_to_doc[idx][\"text\"]\n",
    "        distance = distances[0][i]\n",
    "\n",
    "        print(f\"Rank {i + 1}:\")\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Description: {description}\")\n",
    "        print(f\"Distance: {distance:.4f}\\n\")\n",
    "        context.append(f\"Title: {title}\")\n",
    "        context.append(f\"Description: {description}\")\n",
    "    \n",
    "    print(\"=======================================================================\")\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Generation Strategies\n",
    "\n",
    "This cell introduces multiple strategies for constructing prompts tailored to various language model inference tasks. The design is intended to offer flexibility and control over how context and queries are combined, which is especially valuable when fine-tuning interactions with large language models.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "- **PromptStyle Enum:**  \n",
    "  An enumeration (`PromptStyle`) is defined to encapsulate different prompt formatting strategies, including:\n",
    "  - **STANDARD:** Basic prompt combining context and query.\n",
    "  - **FEW_SHOT:** Adds a few recent Q&A examples to guide the model.\n",
    "  - **CHAIN_OF_THOUGHT:** Encourages step-by-step reasoning.\n",
    "  - **ROLE_BASED:** Frames the query in the context of domain expertise (e.g., forensic investigator).\n",
    "  - **BULLET_POINTS:** Instructs the model to summarize findings in bullet points.\n",
    "  - **SCORING:** Requests the model to score each organization based on risk and provide explanations.\n",
    "  - **CHATML:** Utilizes a ChatML-style formatting for models that require it.\n",
    "\n",
    "- **generate_prompt Function:**  \n",
    "  This function constructs the final prompt by:\n",
    "  1. **Aggregating Context:**  \n",
    "     Joins multiple context documents with clear separation.\n",
    "  2. **Handling Optional History:**  \n",
    "     For few-shot prompting, it appends recent Q&A pairs to enrich the prompt.\n",
    "  3. **Conditionally Formatting the Prompt:**  \n",
    "     Checks the selected `prompt_style` and formats the prompt accordingly, ensuring:\n",
    "     - **Clarity & Structure:** Each version clearly lays out the context, query, and expected model behavior.\n",
    "     - **Adaptability:** Different styles serve different purposes depending on the inference task at hand.\n",
    "\n",
    "This modular approach allows data scientists to experiment with and select the most effective prompting style for their specific use case, helping optimize the quality and relevance of model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "class PromptStyle(Enum):\n",
    "    STANDARD = \"standard\"\n",
    "    FEW_SHOT = \"few_shot\"\n",
    "    CHAIN_OF_THOUGHT = \"chain_of_thought\"\n",
    "    ROLE_BASED = \"role_based\"\n",
    "    BULLET_POINTS = \"bullet_points\"\n",
    "    SCORING = \"scoring\"\n",
    "    CHATML = \"chatml\"\n",
    "\n",
    "\n",
    "def generate_prompt(\n",
    "    query: str,\n",
    "    context_docs: List[str],\n",
    "    prompt_style: PromptStyle = PromptStyle.STANDARD,\n",
    "    # history: List[Tuple[str, str]] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a prompt for the LLM based on the selected prompt style.\n",
    "\n",
    "    Args:\n",
    "        query (str): User's current query.\n",
    "        context_docs (List[str]): Retrieved documents for context.\n",
    "        prompt_style (PromptStyle): The strategy for prompt formatting.\n",
    "        history (List[Tuple[str, str]]): Optional memory of previous Q&A for few-shot examples.\n",
    "\n",
    "    Returns:\n",
    "        str: The final prompt to be sent to the LLM.\n",
    "    \"\"\"\n",
    "    context = \"\\n\\n\".join(context_docs)\n",
    "\n",
    "    if prompt_style == PromptStyle.STANDARD:\n",
    "        return (\n",
    "            \"Your task is to analyse the question based on the context, and then provide an appropriate answer.\\n\\n\"\n",
    "            f\"Context:\\n{context}\\n\\n\"\n",
    "            f\"Question: {query}\\n\\n\"\n",
    "            f\"Answer:\"\n",
    "        )\n",
    "\n",
    "    # if prompt_style == PromptStyle.FEW_SHOT:\n",
    "    #     few_shot_examples = \"\"\n",
    "    #     if history:\n",
    "    #         for past_q, past_a in history[-2:]:  # last 2 examples\n",
    "    #             few_shot_examples += (\n",
    "    #                 f\"Context: [Previous Retrieval]\\n\"\n",
    "    #                 f\"Question: {past_q}\\n\"\n",
    "    #                 f\"Answer: {past_a}\\n\\n\"\n",
    "    #             )\n",
    "        # return (\n",
    "        #     f\"{few_shot_examples}\"\n",
    "        #     f\"Context:\\n{context}\\n\\n\"\n",
    "        #     f\"Question: {query}\\n\\n\"\n",
    "        #     f\"Answer:\"\n",
    "        # )\n",
    "\n",
    "    if prompt_style == PromptStyle.CHAIN_OF_THOUGHT:\n",
    "        return (\n",
    "            f\"Context:\\n{context}\\n\\n\"\n",
    "            f\"Question: {query}\\n\\n\"\n",
    "            f\"Let's think step by step:\"\n",
    "        )\n",
    "\n",
    "    if prompt_style == PromptStyle.ROLE_BASED:\n",
    "        return (\n",
    "            f\"You are a senior forensic investigator specializing in financial crime.\\n\\n\"\n",
    "            f\"Context:\\n{context}\\n\\n\"\n",
    "            f\"Analyze the above organizations for potential risk indicators.\\n\\n\"\n",
    "            f\"Question: {query}\\n\\n\"\n",
    "            f\"Answer:\"\n",
    "        )\n",
    "\n",
    "    if prompt_style == PromptStyle.BULLET_POINTS:\n",
    "        return (\n",
    "            f\"Context:\\n{context}\\n\\n\"\n",
    "            f\"Question: {query}\\n\\n\"\n",
    "            f\"List your findings in bullet points:\\n\"\n",
    "            f\"- \"\n",
    "        )\n",
    "\n",
    "    if prompt_style == PromptStyle.CHATML:\n",
    "        return (\n",
    "            f\"You are a compliance analyst. Based on the context, answer the query thoroughly.\\n\\n\"\n",
    "            f\"Context:\\n{context}\\n\\n\"\n",
    "            f\"Question: {query}\\n\\n\"\n",
    "            f\"Answer:\"\n",
    "        )\n",
    "\n",
    "    raise ValueError(f\"Unsupported prompt style: {prompt_style}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Construction and Mistral Inference Details\n",
    "\n",
    "This cell defines the functions responsible for constructing a prompt for the language model, formatting the prompt for Mistral-Instruct models, and invoking the Hugging Face Inference API to generate a response. The main functions are:\n",
    "\n",
    "1. **build_prompt:**  \n",
    "   - Combines the user's query and the retrieved context into a unified prompt.\n",
    "   - The prompt instructs the model to analyze the context and answer the question.\n",
    "\n",
    "2. **format_chat_prompt:**  \n",
    "   - Wraps the prompt in a ChatML-styled template, which is required by Mistral-Instruct models for proper formatting.\n",
    "\n",
    "3. **call_mistral_hf:**  \n",
    "   - Sends the formatted prompt to the Hugging Face API endpoint for the Mistral model.\n",
    "   - Sets parameters such as temperature and max token output.\n",
    "   - Uses the API token from the environment to authenticate the request.\n",
    "   - Parses and returns the generated text from the API response.\n",
    "\n",
    "> **Note:**  \n",
    "> Ensure that your environment variable `HUGGINGFACE_API_TOKEN` is correctly set in the `.env` file before executing this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Prompt, Format chat prompt and Call Mistral HF\n",
    "#  This cell defines functions to build a prompt for a language model, format it for Mistral-Instruct models,\n",
    "#  and call the Hugging Face Inference API to generate a response.\n",
    "import os\n",
    "from typing import Optional\n",
    "import requests\n",
    "\n",
    "def build_prompt(query: str, context: str,prompt_style=\"standard\") -> str:\n",
    "    \"\"\"\n",
    "    Build a prompt for language model inference based on the given query and context.\n",
    "\n",
    "    Args:\n",
    "        query (str): User query or question.\n",
    "        context (str): Context retrieved from the documents.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted prompt string.\n",
    "    \"\"\"\n",
    "    if prompt_style not in [\n",
    "        PromptStyle.STANDARD,\n",
    "        PromptStyle.FEW_SHOT,\n",
    "        PromptStyle.CHAIN_OF_THOUGHT,\n",
    "        PromptStyle.ROLE_BASED,\n",
    "        PromptStyle.BULLET_POINTS,\n",
    "        PromptStyle.SCORING,\n",
    "        PromptStyle.CHATML,\n",
    "    ]:\n",
    "        raise ValueError(f\"Unsupported prompt style: {prompt_style}\")\n",
    "\n",
    "    prompt = generate_prompt(\n",
    "    query=query,\n",
    "    context_docs=context,\n",
    "    prompt_style=\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def format_chat_prompt(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Format a prompt using ChatML-style for Mistral-Instruct models.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user input to be wrapped.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted prompt suitable for Mistral models.\n",
    "    \"\"\"\n",
    "    return f\"<s>[INST] {prompt.strip()} [/INST]\"\n",
    "\n",
    "\n",
    "def call_mistral_hf(prompt: str, api_token: Optional[str] = os.getenv(\"HUGGINGFACE_API_TOKEN\")) -> str:\n",
    "    \"\"\"\n",
    "    Call the Hugging Face Inference API for the Mistral model with the given prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input prompt for generation.\n",
    "        api_token (Optional[str]): Hugging Face API token. If not provided, will read from env.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response from the model.\n",
    "    \"\"\"\n",
    "    if api_token is None:\n",
    "        api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "\n",
    "    if not api_token:\n",
    "        raise ValueError(\"Hugging Face API token not found. Please set 'HUGGINGFACE_API_TOKEN' in the environment.\")\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    formatted_prompt = format_chat_prompt(prompt)\n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": formatted_prompt,\n",
    "        \"parameters\": {\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_new_tokens\": 512,\n",
    "            \"do_sample\": True,\n",
    "            \"return_full_text\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Make the API call to the Mistral model\n",
    "    api_url = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    return result[0][\"generated_text\"].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End Inference Function Details\n",
    "\n",
    "This cell defines the `inference` function, which ties together all previous functions to run end-to-end inference for a given query. The main steps are:\n",
    "\n",
    "1. **Retrieve Context:**  \n",
    "   - Calls the `search_query` function with the FAISS index and document mapping to retrieve relevant document snippets based on the query.\n",
    "   - Combines the retrieved snippets into a single context string.\n",
    "\n",
    "2. **Prompt Construction:**  \n",
    "   - Utilizes the `build_prompt` function to create a prompt that includes both the query and the context.\n",
    "  \n",
    "3. **Response Generation:**  \n",
    "   - Calls the `call_mistral_hf` function to send the prompt to the Hugging Face Inference API for the Mistral model.\n",
    "   - Returns the generated response from the model.\n",
    "\n",
    "This function encapsulates the complete workflow of the RAG system, making it straightforward to process a user query by retrieving relevant context and generating a human-like answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import faiss\n",
    "\n",
    "\n",
    "def inference(\n",
    "    query: str,\n",
    "    index: faiss.Index,\n",
    "    id_to_docs: Dict[int, Dict[str, Any]],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Run end-to-end inference on a query using a FAISS index and Mistral API.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query to process.\n",
    "        index (faiss.Index): The FAISS index containing document embeddings.\n",
    "        id_to_docs (Dict[int, Dict[str, Any]]): Mapping of index positions to documents.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response from the language model.\n",
    "    \"\"\"\n",
    "    context_list = search_query(index, id_to_docs, query)\n",
    "    # context_str = \"\\n\\n\".join(context_list)\n",
    "    prompt = build_prompt(query, context_list)\n",
    "    return call_mistral_hf(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Creation and Inference Pipeline Overview\n",
    "\n",
    "### FAISS Index Creation:\n",
    "     The cell initializes the FAISS index by calling the `create_faiss_index()` function.  \n",
    "     This function reads and preprocesses the dataset, generates embeddings using a SentenceTransformer model, and builds a FAISS index with L2 distance.  \n",
    "     It also returns a mapping (`id_to_docs`) from index positions to document details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created with 12 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create index\n",
    "index, id_to_docs = create_faiss_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "\"Tell me about Cascade Capital Management?\",\n",
    "\"Which organizations show signs of potential money laundering through complex structures?\",\n",
    "\"What irregular transaction patterns are identified for Aurora Financial Services, and why do these raise concerns about potential money laundering?\",\n",
    "\"How do the described transaction patterns of Blue Horizon Investments hint at possible insider trading or market manipulation?\",\n",
    "\"Compare the descriptions of Falcon Secure Bank and Helix Fintech Solutions. What aspects of their operations contribute to one being perceived as having higher transparency and regulatory compliance than the other?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Inference on Multiple Queries\n",
    "\n",
    "This cell processes a list of queries by executing the end-to-end inference pipeline for each query. The key steps are:\n",
    "\n",
    "- **Iteration Over Queries:**  \n",
    "  Iterates through each query in the `queries` list.\n",
    "\n",
    "- **Printing Query Information:**  \n",
    "  For each query, it prints the query string and a divider for clarity.\n",
    "\n",
    "- **Inference Execution:**  \n",
    "  Calls the `inference` function with the current query, the pre-built FAISS index (`index`), and the document mapping (`id_to_docs`).  \n",
    "  This function retrieves relevant document snippets, constructs a prompt, and obtains a generated response via the Mistral model.\n",
    "\n",
    "- **Response Collection:**  \n",
    "  Appends the generated response to the `responses` list for further use or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Tell me about Cascade Capital Management?\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "Top 3 results retrieved for the Query: Tell me about Cascade Capital Management?\n",
      "=======================================================================\n",
      "Rank 1:\n",
      "Title: Cascade Capital Management\n",
      "Description: Cascade Capital Management, a venture capital firm specializing in tech investments, has grown rapidly but relies on a complex network of subsidiary shell companies. This structure has attracted regulatory scrutiny regarding transparency and compliance.\n",
      "Distance: 0.2569\n",
      "\n",
      "Rank 2:\n",
      "Title: Gemini Asset Management\n",
      "Description: Serving high-net-worth clients in Asia, Gemini Asset Management has recently been spotlighted for unusually high commissions and inconsistent portfolio reporting. These anomalies have sparked concerns over potential money laundering and fraudulent practices.\n",
      "Distance: 0.7213\n",
      "\n",
      "Rank 3:\n",
      "Title: Blue Horizon Investments\n",
      "Description: Based in London, Blue Horizon Investments is known for its innovative portfolio strategies. However, irregular transaction patterns and rapid, unexplained fund movements have raised concerns about possible insider trading and manipulation.\n",
      "Distance: 0.7599\n",
      "\n",
      "=======================================================================\n",
      "Query: Which organizations show signs of potential money laundering through complex structures?\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "Top 3 results retrieved for the Query: Which organizations show signs of potential money laundering through complex structures?\n",
      "=======================================================================\n",
      "Rank 1:\n",
      "Title: Gemini Asset Management\n",
      "Description: Serving high-net-worth clients in Asia, Gemini Asset Management has recently been spotlighted for unusually high commissions and inconsistent portfolio reporting. These anomalies have sparked concerns over potential money laundering and fraudulent practices.\n",
      "Distance: 0.7019\n",
      "\n",
      "Rank 2:\n",
      "Title: Aurora Financial Services\n",
      "Description: Aurora Financial Services, headquartered in New York, is a mid-sized firm that recently recorded an unusually high volume of cross-border transactions with opaque justifications. Analysts have flagged these patterns as potential attempts to obscure money laundering activities.\n",
      "Distance: 0.7182\n",
      "\n",
      "Rank 3:\n",
      "Title: Cascade Capital Management\n",
      "Description: Cascade Capital Management, a venture capital firm specializing in tech investments, has grown rapidly but relies on a complex network of subsidiary shell companies. This structure has attracted regulatory scrutiny regarding transparency and compliance.\n",
      "Distance: 0.8222\n",
      "\n",
      "=======================================================================\n",
      "Query: What irregular transaction patterns are identified for Aurora Financial Services, and why do these raise concerns about potential money laundering?\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "Top 3 results retrieved for the Query: What irregular transaction patterns are identified for Aurora Financial Services, and why do these raise concerns about potential money laundering?\n",
      "=======================================================================\n",
      "Rank 1:\n",
      "Title: Aurora Financial Services\n",
      "Description: Aurora Financial Services, headquartered in New York, is a mid-sized firm that recently recorded an unusually high volume of cross-border transactions with opaque justifications. Analysts have flagged these patterns as potential attempts to obscure money laundering activities.\n",
      "Distance: 0.4129\n",
      "\n",
      "Rank 2:\n",
      "Title: Gemini Asset Management\n",
      "Description: Serving high-net-worth clients in Asia, Gemini Asset Management has recently been spotlighted for unusually high commissions and inconsistent portfolio reporting. These anomalies have sparked concerns over potential money laundering and fraudulent practices.\n",
      "Distance: 0.6401\n",
      "\n",
      "Rank 3:\n",
      "Title: Ionex Brokerage Services\n",
      "Description: Ionex Brokerage Services is a popular online platform in Europe with a proven track record of consistent performance. Its transaction patterns are steady and well-documented, with no known irregularities or red flags in its operations.\n",
      "Distance: 0.7513\n",
      "\n",
      "=======================================================================\n",
      "Query: How do the described transaction patterns of Blue Horizon Investments hint at possible insider trading or market manipulation?\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "Top 3 results retrieved for the Query: How do the described transaction patterns of Blue Horizon Investments hint at possible insider trading or market manipulation?\n",
      "=======================================================================\n",
      "Rank 1:\n",
      "Title: Blue Horizon Investments\n",
      "Description: Based in London, Blue Horizon Investments is known for its innovative portfolio strategies. However, irregular transaction patterns and rapid, unexplained fund movements have raised concerns about possible insider trading and manipulation.\n",
      "Distance: 0.4349\n",
      "\n",
      "Rank 2:\n",
      "Title: Gemini Asset Management\n",
      "Description: Serving high-net-worth clients in Asia, Gemini Asset Management has recently been spotlighted for unusually high commissions and inconsistent portfolio reporting. These anomalies have sparked concerns over potential money laundering and fraudulent practices.\n",
      "Distance: 0.6969\n",
      "\n",
      "Rank 3:\n",
      "Title: Cascade Capital Management\n",
      "Description: Cascade Capital Management, a venture capital firm specializing in tech investments, has grown rapidly but relies on a complex network of subsidiary shell companies. This structure has attracted regulatory scrutiny regarding transparency and compliance.\n",
      "Distance: 0.8243\n",
      "\n",
      "=======================================================================\n",
      "Query: Compare the descriptions of Falcon Secure Bank and Helix Fintech Solutions. What aspects of their operations contribute to one being perceived as having higher transparency and regulatory compliance than the other?\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "Top 3 results retrieved for the Query: Compare the descriptions of Falcon Secure Bank and Helix Fintech Solutions. What aspects of their operations contribute to one being perceived as having higher transparency and regulatory compliance than the other?\n",
      "=======================================================================\n",
      "Rank 1:\n",
      "Title: Falcon Secure Bank\n",
      "Description: Falcon Secure Bank is a digital-only institution acclaimed for its cutting-edge cybersecurity and rigorous internal audits. The bank consistently demonstrates strong compliance practices and transparent operations, earning the trust of its customers and regulators alike.\n",
      "Distance: 0.4451\n",
      "\n",
      "Rank 2:\n",
      "Title: Helix Fintech Solutions\n",
      "Description: Helix Fintech Solutions is a rapidly growing startup in the financial technology space. Its strategy of partnering with numerous unregulated advisors has resulted in a patchwork of compliance practices, prompting internal reviews for potential fraud and mismanagement of client funds.\n",
      "Distance: 0.4689\n",
      "\n",
      "Rank 3:\n",
      "Title: Kepler Financial Innovations\n",
      "Description: Kepler Financial Innovations is renowned for its ethical practices and state-of-the-art risk management. With a focus on transparency and regulatory compliance, the firm has built a reputation as a trusted player in the financial market.\n",
      "Distance: 0.7404\n",
      "\n",
      "=======================================================================\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for query in queries:\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"=======================================================================\")\n",
    "    # Run inference for each query\n",
    "    response = inference(query, index, id_to_docs)\n",
    "    responses.append(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Generated Responses\n",
    "\n",
    "This cell is responsible for presenting the generated responses in a readable format. The steps involved are:\n",
    "\n",
    "1. **Iterating Over Responses:**  \n",
    "   - Loops through each response stored in the `responses` list.\n",
    "\n",
    "2. **Rendering Responses in HTML:**  \n",
    "   - Uses the `IPython.display` module to render each response within an HTML `<div>` container.  \n",
    "   - The HTML container is styled with `white-space: pre-wrap` to ensure proper word wrapping.\n",
    "\n",
    "This ensures that the output is easily readable and neatly formatted within the Jupyter Notebook interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap; word-wrap: break-word;'>Cascade Capital Management is a venture capital firm that specializes in tech investments. They have experienced significant growth but have come under regulatory scrutiny due to their complex network of subsidiary shell companies. This structure has raised concerns about transparency and compliance within the firm.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap; word-wrap: break-word;'>Based on the context provided, Gemini Asset Management in Asia, Aurora Financial Services in New York, and Cascade Capital Management are the organizations that show signs of potential money laundering through complex structures. Gemini Asset Management has been highlighted for unusually high commissions and inconsistent portfolio reporting, which have raised concerns over potential money laundering and fraudulent practices. Aurora Financial Services, on the other hand, has recorded an unusually high volume of cross-border transactions with opaque justifications, which have been flagged as potential attempts to obscure money laundering activities. Lastly, Cascade Capital Management, a venture capital firm specializing in tech investments, has grown rapidly but relies on a complex network of subsidiary shell companies. This structure has attracted regulatory scrutiny regarding transparency and compliance.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap; word-wrap: break-word;'>The irregular transaction patterns identified for Aurora Financial Services include an unusually high volume of cross-border transactions with opaque justifications. These transactions raise concerns about potential money laundering activities because cross-border transactions can be used to move illegally-gained proceeds across borders to disguise their origin. Opaque justifications, on the other hand, make it difficult to understand the reason behind the transactions, which can be a red flag for money laundering as it is often used to hide the true nature of the funds being transferred. Analysts have flagged these patterns due to their potential to obscure illegal activities.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap; word-wrap: break-word;'>The irregular transaction patterns and rapid, unexplained fund movements described in the context of Blue Horizon Investments could hint at possible insider trading or market manipulation in several ways. Insider trading refers to buying or selling securities based on material, non-public information. Market manipulation involves artificially influencing the price of a security through illegal means.\n",
       "\n",
       "1. Insider trading: If Blue Horizon Investments' employees or associates have access to non-public information about a company, they could use this information to make trades before the information is publicly available. The rapid, unexplained fund movements could suggest that insiders are taking advantage of this information to buy or sell securities, potentially at the expense of other investors.\n",
       "2. Market manipulation: Market manipulation can take various forms, such as pump-and-dump schemes or spoofing. Irregular transaction patterns, such as large, unusual trades, could indicate an attempt to manipulate the market price of a security. For example, a large purchase of a security could artificially inflate the price, allowing insiders to sell at a profit before the price reverts to its true value.\n",
       "\n",
       "It's important to note that these are potential indicators of insider trading or market manipulation, and further investigation would be required to confirm any wrongdoing. Regulatory bodies and law enforcement agencies have the authority to investigate these matters and take appropriate action if they find evidence of illegal activity.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap; word-wrap: break-word;'>Based on the provided context, the descriptions of Falcon Secure Bank and Helix Fintech Solutions suggest that Falcon Secure Bank is perceived to have higher transparency and regulatory compliance compared to Helix Fintech Solutions for several reasons. Firstly, Falcon Secure Bank is a digital-only institution with a consistent track record of strong compliance practices and rigorous internal audits. This demonstrates a commitment to adhering to regulatory requirements and maintaining transparent operations, which in turn builds trust with its customers and regulators.\n",
       "\n",
       "On the other hand, Helix Fintech Solutions is described as a rapidly growing startup in the financial technology space that has partnered with numerous unregulated advisors. This approach has resulted in a patchwork of compliance practices, which has prompted internal reviews for potential fraud and mismanagement of client funds. The lack of consistent regulatory compliance and the presence of unregulated advisors may contribute to a perception of lower transparency and increased risk for Helix Fintech Solutions.\n",
       "\n",
       "Therefore, the key aspects of their operations that contribute to one being perceived as having higher transparency and regulatory compliance than the other are Falcon Secure Bank's consistent compliance practices, rigorous internal audits, and digital-only status, compared to Helix Fintech Solutions' patchwork of compliance practices, partnerships with unregulated advisors, and resulting internal reviews for potential fraud and mismanagement of client funds.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "for response in responses:\n",
    "    # Display the response in plain text\n",
    "    # print(responses)\n",
    "    \n",
    "    # To display it as wrapped HTML\n",
    "    display(HTML(f\"<div style='white-space: pre-wrap; word-wrap: break-word;'>{response}</div>\"))\n",
    "    print(\"=======================================================================\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
